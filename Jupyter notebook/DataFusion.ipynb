{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0099f7b3-5318-4d7a-9eed-3c743c29c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f742e88-5b5a-485d-b901-e55fe179ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for NSL-KDD dataset\n",
    "nsl_kdd_columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
    "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
    "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "# Load the datasets with column names\n",
    "nsl_train = pd.read_csv('KDDTrain+.txt', header=None, names=nsl_kdd_columns)\n",
    "nsl_test = pd.read_csv('KDDTest+.txt', header=None, names=nsl_kdd_columns)\n",
    "unsw_train = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "unsw_test = pd.read_csv('UNSW_NB15_testing-set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762c98a7-702d-4562-9a2d-95d1daec9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and select features\n",
    "def preprocess_and_select_features(train_data, test_data, target_column, n_features=13):\n",
    "    # Separate features and labels\n",
    "    if isinstance(target_column, int):\n",
    "        X_train = train_data.iloc[:, :-1]\n",
    "        y_train = train_data.iloc[:, -1]\n",
    "        X_test = test_data.iloc[:, :-1]\n",
    "        y_test = test_data.iloc[:, -1]\n",
    "    else:\n",
    "        X_train = train_data.drop(target_column, axis=1)\n",
    "        y_train = train_data[target_column]\n",
    "        X_test = test_data.drop(target_column, axis=1)\n",
    "        y_test = test_data[target_column]\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    for column in X_train.select_dtypes(include=['object']).columns:\n",
    "        # Combine train and test data for encoding\n",
    "        all_data = pd.concat([X_train[column], X_test[column]], axis=0)\n",
    "        le = LabelEncoder()\n",
    "        le.fit(all_data.astype(str))\n",
    "        \n",
    "        # Transform both train and test data\n",
    "        X_train[column] = le.transform(X_train[column].astype(str))\n",
    "        X_test[column] = le.transform(X_test[column].astype(str))\n",
    "    \n",
    "    # Handle any remaining non-numeric columns\n",
    "    X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "    X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Impute any NaN values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    # Perform feature selection using RFE with Random Forest\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    selector = RFE(estimator=rfc, n_features_to_select=n_features, step=1)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = X_train.columns[selector.support_].tolist()\n",
    "    \n",
    "    # Apply feature selection to both train and test sets\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "    \n",
    "    return X_train_selected, y_train, X_test_selected, y_test, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65ffa9c-4a4f-49ab-9d74-1f3524044ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for NSL-KDD:\n",
      "['protocol_type', 'flag', 'src_bytes', 'num_failed_logins', 'is_guest_login', 'count', 'srv_rerror_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_srv_rerror_rate']\n",
      "\n",
      "Selected features for UNSW-NB15:\n",
      "['id', 'sbytes', 'dbytes', 'rate', 'sttl', 'sload', 'tcprtt', 'smean', 'ct_state_ttl', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'ct_srv_dst', 'attack_cat']\n"
     ]
    }
   ],
   "source": [
    "# Sample a subset of the data\n",
    "nsl_train_sample = nsl_train.sample(frac=0.1, random_state=42)\n",
    "nsl_test_sample = nsl_test.sample(frac=0.1, random_state=42)\n",
    "unsw_train_sample = unsw_train.sample(frac=0.1, random_state=42)\n",
    "unsw_test_sample = unsw_test.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Perform feature selection on the sampled data\n",
    "nsl_X_train, nsl_y_train, nsl_X_test, nsl_y_test, nsl_selected_features = preprocess_and_select_features(nsl_train_sample, nsl_test_sample, -1)\n",
    "unsw_X_train, unsw_y_train, unsw_X_test, unsw_y_test, unsw_selected_features = preprocess_and_select_features(unsw_train_sample, unsw_test_sample, 'label')\n",
    "\n",
    "# Print selected features\n",
    "print(\"Selected features for NSL-KDD:\")\n",
    "print(nsl_selected_features)\n",
    "print(\"\\nSelected features for UNSW-NB15:\")\n",
    "print(unsw_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee287cc-b63e-44e0-83da-18e9b8cd3322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for NSL-KDD:\n",
      "['protocol_type', 'flag', 'src_bytes', 'num_failed_logins', 'is_guest_login', 'count', 'srv_rerror_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_srv_rerror_rate']\n",
      "\n",
      "Selected features for UNSW-NB15:\n",
      "['id', 'dur', 'sbytes', 'dbytes', 'rate', 'sttl', 'sload', 'synack', 'ct_state_ttl', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'ct_srv_dst', 'attack_cat']\n"
     ]
    }
   ],
   "source": [
    "# Perform feature selection for NSL-KDD\n",
    "nsl_X_train, nsl_y_train, nsl_X_test, nsl_y_test, nsl_selected_features = preprocess_and_select_features(nsl_train, nsl_test, 'label')\n",
    "\n",
    "# Perform feature selection for UNSW-NB15\n",
    "unsw_X_train, unsw_y_train, unsw_X_test, unsw_y_test, unsw_selected_features = preprocess_and_select_features(unsw_train, unsw_test, 'label')\n",
    "\n",
    "# Print selected features\n",
    "print(\"Selected features for NSL-KDD:\")\n",
    "print(nsl_selected_features)\n",
    "print(\"\\nSelected features for UNSW-NB15:\")\n",
    "print(unsw_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5057b222-0b23-46c1-8b0e-36c344ac12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_fusion(X, y, selected_features, dataset_name):\n",
    "    # Reset index to avoid duplicate index issues\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    # Add dataset identifier\n",
    "    X['dataset'] = dataset_name\n",
    "    \n",
    "    # Ensure all selected features are present\n",
    "    for feature in selected_features:\n",
    "        if feature not in X.columns:\n",
    "            X[feature] = 0  # or some other appropriate default value\n",
    "    \n",
    "    # Select only the chosen features\n",
    "    X_selected = X[selected_features + ['dataset']]\n",
    "    \n",
    "    # Combine features and label\n",
    "    df = pd.concat([X_selected, y], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5dbeb57-aef8-4344-8eda-c328e259a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for fusion\n",
    "nsl_train_prepared = prepare_for_fusion(nsl_X_train, nsl_y_train, nsl_selected_features, 'NSL-KDD')\n",
    "nsl_test_prepared = prepare_for_fusion(nsl_X_test, nsl_y_test, nsl_selected_features, 'NSL-KDD')\n",
    "unsw_train_prepared = prepare_for_fusion(unsw_X_train, unsw_y_train, unsw_selected_features, 'UNSW-NB15')\n",
    "unsw_test_prepared = prepare_for_fusion(unsw_X_test, unsw_y_test, unsw_selected_features, 'UNSW-NB15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d0c8398-883c-4dc4-871e-e130086fbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "import pandas as pd\n",
    "\n",
    "fused_train = pd.concat([nsl_train_prepared, unsw_train_prepared], ignore_index=True)\n",
    "fused_test = pd.concat([nsl_test_prepared, unsw_test_prepared], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89a5be7f-50d6-4122-9966-a5c3b1eb25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = fused_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'label' in numerical_columns:\n",
    "    numerical_columns.remove('label')  # Exclude the label column from scaling\n",
    "\n",
    "fused_train[numerical_columns] = scaler.fit_transform(fused_train[numerical_columns])\n",
    "fused_test[numerical_columns] = scaler.transform(fused_test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33d3c057-63eb-41ec-a506-3d1765f5605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fused training dataset shape: (208305, 28)\n",
      "Fused testing dataset shape: (197885, 28)\n",
      "\n",
      "Fused dataset columns: ['protocol_type', 'flag', 'src_bytes', 'num_failed_logins', 'is_guest_login', 'count', 'srv_rerror_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_srv_rerror_rate', 'dataset', 'label', 'id', 'dur', 'sbytes', 'dbytes', 'rate', 'sttl', 'sload', 'synack', 'ct_state_ttl', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'ct_srv_dst', 'attack_cat']\n"
     ]
    }
   ],
   "source": [
    "# Save fused datasets\n",
    "fused_train.to_csv('fused_train_dataset.csv', index=False)\n",
    "fused_test.to_csv('fused_test_dataset.csv', index=False)\n",
    "\n",
    "print(\"\\nFused training dataset shape:\", fused_train.shape)\n",
    "print(\"Fused testing dataset shape:\", fused_test.shape)\n",
    "print(\"\\nFused dataset columns:\", fused_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "800b978a-c7a9-4783-ae9b-78a927c730c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fused dataset\n",
    "fused_train = pd.read_csv('fused_train_dataset.csv')\n",
    "fused_test = pd.read_csv('fused_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0296c6ad-6102-464b-a3bc-c962bd36c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = fused_train.drop(['label', 'dataset'], axis=1)\n",
    "y = fused_train['label']\n",
    "\n",
    "X_test = fused_test.drop(['label', 'dataset'], axis=1)\n",
    "y_test = fused_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "833555be-a861-4f7a-be44-3ffc8415e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "037f475f-ee14-4b82-a26a-92c5aba3ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a646af2-1675-4473-8cc5-60b3517626a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a796b38-ad77-4336-85c8-f15d97502a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "models = {\n",
    "    'SVM': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02ee0db3-5855-4a1e-9c8b-d54e92da992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8005f982-a159-4ea8-95f9-865d2b180765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalmr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Validation Results:\n",
      "Accuracy: 0.8241\n",
      "Precision: 0.8151\n",
      "Recall: 0.8241\n",
      "F1-score: 0.8015\n",
      "Cross-validation scores: [0.81798325 0.82628838 0.76121553 0.82480017 0.82626437]\n",
      "Mean CV score: 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalmr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Test Results:\n",
      "Accuracy: 0.8643\n",
      "Precision: 0.8818\n",
      "Recall: 0.8643\n",
      "F1-score: 0.8633\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree - Validation Results:\n",
      "Accuracy: 0.9188\n",
      "Precision: 0.9192\n",
      "Recall: 0.9188\n",
      "F1-score: 0.9189\n",
      "Cross-validation scores: [0.91534049 0.91889297 0.92110127 0.92033317 0.91891697]\n",
      "Mean CV score: 0.9189\n",
      "Decision Tree - Test Results:\n",
      "Accuracy: 0.9574\n",
      "Precision: 0.9536\n",
      "Recall: 0.9574\n",
      "F1-score: 0.9548\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest - Validation Results:\n",
      "Accuracy: 0.9288\n",
      "Precision: 0.9277\n",
      "Recall: 0.9288\n",
      "F1-score: 0.9279\n",
      "Cross-validation scores: [0.92532584 0.92861429 0.93058256 0.93034253 0.92525383]\n",
      "Mean CV score: 0.9280\n",
      "Random Forest - Test Results:\n",
      "Accuracy: 0.9138\n",
      "Precision: 0.9133\n",
      "Recall: 0.9138\n",
      "F1-score: 0.9098\n",
      "\n",
      "Training KNN...\n",
      "KNN - Validation Results:\n",
      "Accuracy: 0.9094\n",
      "Precision: 0.9085\n",
      "Recall: 0.9094\n",
      "F1-score: 0.9088\n",
      "Cross-validation scores: [0.90254675 0.90981974 0.85761264 0.91113992 0.9087876 ]\n",
      "Mean CV score: 0.8980\n",
      "KNN - Test Results:\n",
      "Accuracy: 0.7027\n",
      "Precision: 0.8191\n",
      "Recall: 0.7027\n",
      "F1-score: 0.7071\n",
      "\n",
      "Training Naive Bayes...\n",
      "Naive Bayes - Validation Results:\n",
      "Accuracy: 0.7100\n",
      "Precision: 0.7088\n",
      "Recall: 0.7100\n",
      "F1-score: 0.6943\n",
      "Cross-validation scores: [0.67919637 0.7007033  0.69218214 0.70161542 0.68361297]\n",
      "Mean CV score: 0.6915\n",
      "Naive Bayes - Test Results:\n",
      "Accuracy: 0.9306\n",
      "Precision: 0.9369\n",
      "Recall: 0.9306\n",
      "F1-score: 0.9304\n",
      "\n",
      "Summary of Results:\n",
      "\n",
      "SVM:\n",
      "Validation Accuracy: 0.8241\n",
      "Cross-Validation Score: 0.8113\n",
      "Test Accuracy: 0.8643\n",
      "\n",
      "Decision Tree:\n",
      "Validation Accuracy: 0.9188\n",
      "Cross-Validation Score: 0.9189\n",
      "Test Accuracy: 0.9574\n",
      "\n",
      "Random Forest:\n",
      "Validation Accuracy: 0.9288\n",
      "Cross-Validation Score: 0.9280\n",
      "Test Accuracy: 0.9138\n",
      "\n",
      "KNN:\n",
      "Validation Accuracy: 0.9094\n",
      "Cross-Validation Score: 0.8980\n",
      "Test Accuracy: 0.7027\n",
      "\n",
      "Naive Bayes:\n",
      "Validation Accuracy: 0.7100\n",
      "Cross-Validation Score: 0.6915\n",
      "Test Accuracy: 0.9306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalmr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    accuracy, precision, recall, f1 = evaluate_model(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"{name} - Validation Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    print(f\"Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"Mean CV score: {cv_scores.mean():.4f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"{name} - Test Results:\")\n",
    "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print(f\"Recall: {test_recall:.4f}\")\n",
    "    print(f\"F1-score: {test_f1:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'validation': {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1},\n",
    "        'cv_score': cv_scores.mean(),\n",
    "        'test': {'accuracy': test_accuracy, 'precision': test_precision, 'recall': test_recall, 'f1': test_f1}\n",
    "    }\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nSummary of Results:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Validation Accuracy: {result['validation']['accuracy']:.4f}\")\n",
    "    print(f\"Cross-Validation Score: {result['cv_score']:.4f}\")\n",
    "    print(f\"Test Accuracy: {result['test']['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07c7a5aa-afe0-4fb2-9ec2-74b8e99467d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for NSL-KDD dataset\n",
    "nsl_kdd_columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
    "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
    "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "# Load the datasets with column names\n",
    "nsl_train = pd.read_csv('KDDTrain+.txt', header=None, names=nsl_kdd_columns)\n",
    "nsl_test = pd.read_csv('KDDTest+.txt', header=None, names=nsl_kdd_columns)\n",
    "unsw_train = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "unsw_test = pd.read_csv('UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b8d4fb2-833a-49c9-aa53-8db902e96fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data, target_column):\n",
    "    # Separate features and labels\n",
    "    X_train = train_data.drop(target_column, axis=1)\n",
    "    y_train = train_data[target_column]\n",
    "    X_test = test_data.drop(target_column, axis=1)\n",
    "    y_test = test_data[target_column]\n",
    "\n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    for column in X_train.select_dtypes(include=['object']).columns:\n",
    "        X_train[column] = le.fit_transform(X_train[column].astype(str))\n",
    "        X_test[column] = le.transform(X_test[column].astype(str))\n",
    "    \n",
    "    # Handle any remaining non-numeric columns\n",
    "    X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "    X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Impute any NaN values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "    # Preprocess NSL-KDD dataset\n",
    "    nsl_X_train, nsl_y_train, nsl_X_test, nsl_y_test = preprocess_data(nsl_train, nsl_test, 'label')\n",
    "\n",
    "    # Preprocess UNSW-NB15 dataset\n",
    "    unsw_X_train, unsw_y_train, unsw_X_test, unsw_y_test = preprocess_data(unsw_train, unsw_test, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad677017-38a6-44ab-aa76-270bb6c4eaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models on NSL-KDD dataset:\n",
      "\n",
      "Training SVM on NSL-KDD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalmr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Validation Results:\n",
      "Accuracy: 0.4744\n",
      "Precision: 0.2330\n",
      "Recall: 0.4744\n",
      "F1-score: 0.3054\n",
      "\n",
      "Training Decision Tree on NSL-KDD...\n",
      "Decision Tree - Validation Results:\n",
      "Accuracy: 0.6324\n",
      "Precision: 0.5837\n",
      "Recall: 0.6324\n",
      "F1-score: 0.5999\n",
      "\n",
      "Training Random Forest on NSL-KDD...\n",
      "Random Forest - Validation Results:\n",
      "Accuracy: 0.6422\n",
      "Precision: 0.5872\n",
      "Recall: 0.6422\n",
      "F1-score: 0.6000\n",
      "\n",
      "Training KNN on NSL-KDD...\n",
      "KNN - Validation Results:\n",
      "Accuracy: 0.6123\n",
      "Precision: 0.5380\n",
      "Recall: 0.6123\n",
      "F1-score: 0.5601\n",
      "\n",
      "Training Naive Bayes on NSL-KDD...\n",
      "Naive Bayes - Validation Results:\n",
      "Accuracy: 0.4727\n",
      "Precision: 0.2657\n",
      "Recall: 0.4727\n",
      "F1-score: 0.3160\n",
      "\n",
      "Evaluating models on UNSW-NB15 dataset:\n",
      "\n",
      "Training SVM on UNSW-NB15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalmr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Validation Results:\n",
      "Accuracy: 0.7110\n",
      "Precision: 0.8241\n",
      "Recall: 0.7110\n",
      "F1-score: 0.7188\n",
      "\n",
      "Training Decision Tree on UNSW-NB15...\n",
      "Decision Tree - Validation Results:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-score: 1.0000\n",
      "\n",
      "Training Random Forest on UNSW-NB15...\n",
      "Random Forest - Validation Results:\n",
      "Accuracy: 0.9524\n",
      "Precision: 0.9586\n",
      "Recall: 0.9524\n",
      "F1-score: 0.9532\n",
      "\n",
      "Training KNN on UNSW-NB15...\n",
      "KNN - Validation Results:\n",
      "Accuracy: 0.7252\n",
      "Precision: 0.7771\n",
      "Recall: 0.7252\n",
      "F1-score: 0.7344\n",
      "\n",
      "Training Naive Bayes on UNSW-NB15...\n",
      "Naive Bayes - Validation Results:\n",
      "Accuracy: 0.3543\n",
      "Precision: 0.6407\n",
      "Recall: 0.3543\n",
      "F1-score: 0.2434\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'SVM': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Train and evaluate models on NSL-KDD dataset\n",
    "print(\"\\nEvaluating models on NSL-KDD dataset:\")\n",
    "nsl_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} on NSL-KDD...\")\n",
    "    model.fit(nsl_X_train, nsl_y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(nsl_X_test)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    accuracy, precision, recall, f1 = evaluate_model(nsl_y_test, y_val_pred)\n",
    "    \n",
    "    print(f\"{name} - Validation Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    nsl_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Train and evaluate models on UNSW-NB15 dataset\n",
    "print(\"\\nEvaluating models on UNSW-NB15 dataset:\")\n",
    "unsw_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} on UNSW-NB15...\")\n",
    "    model.fit(unsw_X_train, unsw_y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(unsw_X_test)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    accuracy, precision, recall, f1 = evaluate_model(unsw_y_test, y_val_pred)\n",
    "    \n",
    "    print(f\"{name} - Validation Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    unsw_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "342d97d4-165e-417c-8619-2cee5b96e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results on NSL-KDD dataset:\n",
      "\n",
      "SVM:\n",
      "Accuracy: 0.4744\n",
      "Precision: 0.2330\n",
      "Recall: 0.4744\n",
      "F1-score: 0.3054\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.6324\n",
      "Precision: 0.5837\n",
      "Recall: 0.6324\n",
      "F1-score: 0.5999\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6422\n",
      "Precision: 0.5872\n",
      "Recall: 0.6422\n",
      "F1-score: 0.6000\n",
      "\n",
      "KNN:\n",
      "Accuracy: 0.6123\n",
      "Precision: 0.5380\n",
      "Recall: 0.6123\n",
      "F1-score: 0.5601\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy: 0.4727\n",
      "Precision: 0.2657\n",
      "Recall: 0.4727\n",
      "F1-score: 0.3160\n",
      "\n",
      "Summary of Results on UNSW-NB15 dataset:\n",
      "\n",
      "SVM:\n",
      "Accuracy: 0.7110\n",
      "Precision: 0.8241\n",
      "Recall: 0.7110\n",
      "F1-score: 0.7188\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-score: 1.0000\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9524\n",
      "Precision: 0.9586\n",
      "Recall: 0.9524\n",
      "F1-score: 0.9532\n",
      "\n",
      "KNN:\n",
      "Accuracy: 0.7252\n",
      "Precision: 0.7771\n",
      "Recall: 0.7252\n",
      "F1-score: 0.7344\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy: 0.3543\n",
      "Precision: 0.6407\n",
      "Recall: 0.3543\n",
      "F1-score: 0.2434\n",
      "\n",
      "Summary of Results on Fused dataset:\n",
      "\n",
      "SVM:\n",
      "Validation Accuracy: 0.8241\n",
      "Cross-Validation Score: 0.8113\n",
      "Test Accuracy: 0.8643\n",
      "Precision: 0.8818\n",
      "Recall: 0.8643\n",
      "F1-score: 0.8633\n",
      "\n",
      "Decision Tree:\n",
      "Validation Accuracy: 0.9188\n",
      "Cross-Validation Score: 0.9189\n",
      "Test Accuracy: 0.9574\n",
      "Precision: 0.9536\n",
      "Recall: 0.9574\n",
      "F1-score: 0.9548\n",
      "\n",
      "Random Forest:\n",
      "Validation Accuracy: 0.9288\n",
      "Cross-Validation Score: 0.9280\n",
      "Test Accuracy: 0.9138\n",
      "Precision: 0.9133\n",
      "Recall: 0.9138\n",
      "F1-score: 0.9098\n",
      "\n",
      "KNN:\n",
      "Validation Accuracy: 0.9094\n",
      "Cross-Validation Score: 0.8980\n",
      "Test Accuracy: 0.7027\n",
      "Precision: 0.8191\n",
      "Recall: 0.7027\n",
      "F1-score: 0.7071\n",
      "\n",
      "Naive Bayes:\n",
      "Validation Accuracy: 0.7100\n",
      "Cross-Validation Score: 0.6915\n",
      "Test Accuracy: 0.9306\n",
      "Precision: 0.9369\n",
      "Recall: 0.9306\n",
      "F1-score: 0.9304\n"
     ]
    }
   ],
   "source": [
    "# Print summary of results\n",
    "print(\"\\nSummary of Results on NSL-KDD dataset:\")\n",
    "for name, result in nsl_results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {result['precision']:.4f}\")\n",
    "    print(f\"Recall: {result['recall']:.4f}\")\n",
    "    print(f\"F1-score: {result['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nSummary of Results on UNSW-NB15 dataset:\")\n",
    "for name, result in unsw_results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {result['precision']:.4f}\")\n",
    "    print(f\"Recall: {result['recall']:.4f}\")\n",
    "    print(f\"F1-score: {result['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nSummary of Results on Fused dataset:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Validation Accuracy: {result['validation']['accuracy']:.4f}\")\n",
    "    print(f\"Cross-Validation Score: {result['cv_score']:.4f}\")\n",
    "    print(f\"Test Accuracy: {result['test']['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {result['test']['precision']:.4f}\")\n",
    "    print(f\"Recall: {result['test']['recall']:.4f}\")\n",
    "    print(f\"F1-score: {result['test']['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a77ccb-649f-4603-b252-4545a6921e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
